{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGXzL0+zIpYd5fjkJS5TLw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliba12/Deep-Learning-GEN/blob/main%2FDeep-Learning-%26-GEN/NLP_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr9zdlBDwOpz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Is text positive or not? for checking reviews or spam emails\n",
        "##\n",
        "reviews = [\n",
        "  \"This movie was a breath of fresh air! The acting was superb, and the story kept me guessing until the very end.\",\n",
        "  \"The dialogue was cheesy and the plot predictable. A forgettable movie.\",\n",
        "  \"A visually stunning film with a powerful message. A must-watch for any sci-fi fan.\",\n",
        "  \"The acting was wooden and the special effects looked cheap. A disappointment.\",\n",
        "  \"A hilarious comedy that had me laughing out loud throughout. Perfect for a pick-me-up.\",\n",
        "  \"The pacing was slow and the ending felt rushed. Not my cup of tea.\",\n",
        "  \"A thought-provoking documentary that will stay with you long after the credits roll.\",\n",
        "  \"The characters were underdeveloped and the story lacked depth. Skippable.\",\n",
        "  \"A delightful family film with something for everyone. A great choice for a movie night.\",\n",
        "  \"The acting was phenomenal and the story was heartbreaking. A truly moving film.\",\n",
        "  # ... (remaining reviews, excluding reviews with mixed sentiment) ...\n",
        "  \"This historical drama captured the essence of the time period beautifully.\",\n",
        "  \"The cinematography was stunning, but the plot was convoluted.\",\n",
        "  \"A heartwarming story about overcoming adversity. A tearjerker!\",\n",
        "  \"The acting was so bad it was good. A cult classic in the making.\",\n",
        "  \"A thought-provoking film that challenges societal norms. Must-see for social commentary fans.\",\n",
        "  \"The special effects were groundbreaking, but the story lacked emotional depth.\",\n",
        "  \"A well-paced and suspenseful thriller that will keep you guessing.\",\n",
        "  \"The acting was phenomenal, but the ending felt rushed and unsatisfying.\",\n",
        "  \"A heartwarming comedy that will leave you with a smile. Perfect for a feel-good night.\",\n",
        "  \"The animation was beautiful, but the characters were forgettable.\",\n",
        "  \"A documentary that sheds light on a critical issue. A must-watch for anyone concerned about the topic.\",\n",
        "]\n",
        "labels = [\n",
        "  1,  # Positive\n",
        "  0,  # Negative\n",
        "  1,  # Positive\n",
        "  0,  # Negative\n",
        "  1,  # Positive\n",
        "  0,  # Negative\n",
        "  1,  # Positive\n",
        "  0,  # Negative\n",
        "  1,  # Positive\n",
        "  1,  # Positive\n",
        "  # ... (remaining labels, excluding labels for reviews with mixed sentiment) ...\n",
        "  1,  # Positive\n",
        "  0,  # Negative\n",
        "  1,  # Positive\n",
        "  1,  # Positive (assuming the review leans positive)\n",
        "  1,  # Positive\n",
        "  0,  # Negative\n",
        "  1,  # Positive\n",
        "  0,  # Negative\n",
        "  1,  # Positive\n",
        "  0,  # Negative\n",
        "  1,  # Positive\n",
        "]\n",
        "\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "W6pLsfOpwu3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQSIk2sIXZoJ",
        "outputId": "479bc38e-1e34-4393-a7b3-27086ea96747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##  Tokenize the reviews (convert wordszaaaazaa  to integer IDs)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=1000)   # Adjust num_words as needed\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "sequences = tokenizer.texts_to_sequences(reviews)"
      ],
      "metadata": {
        "id": "J8lquDcDXkbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index      # Mapping of words to their integer IDs\n",
        "                          # Attribute"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gb0tsqIla_7h",
        "outputId": "f27916d4-3558-4749-f380-44672c115003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'a': 2,\n",
              " 'was': 3,\n",
              " 'and': 4,\n",
              " 'for': 5,\n",
              " 'that': 6,\n",
              " 'acting': 7,\n",
              " 'story': 8,\n",
              " 'film': 9,\n",
              " 'with': 10,\n",
              " 'but': 11,\n",
              " 'movie': 12,\n",
              " 'of': 13,\n",
              " 'me': 14,\n",
              " 'must': 15,\n",
              " 'will': 16,\n",
              " 'you': 17,\n",
              " 'were': 18,\n",
              " 'this': 19,\n",
              " 'guessing': 20,\n",
              " 'plot': 21,\n",
              " 'forgettable': 22,\n",
              " 'stunning': 23,\n",
              " 'watch': 24,\n",
              " 'special': 25,\n",
              " 'effects': 26,\n",
              " 'comedy': 27,\n",
              " 'perfect': 28,\n",
              " 'ending': 29,\n",
              " 'felt': 30,\n",
              " 'rushed': 31,\n",
              " 'thought': 32,\n",
              " 'provoking': 33,\n",
              " 'documentary': 34,\n",
              " 'characters': 35,\n",
              " 'lacked': 36,\n",
              " 'depth': 37,\n",
              " 'night': 38,\n",
              " 'phenomenal': 39,\n",
              " 'heartwarming': 40,\n",
              " 'about': 41,\n",
              " 'good': 42,\n",
              " 'breath': 43,\n",
              " 'fresh': 44,\n",
              " 'air': 45,\n",
              " 'superb': 46,\n",
              " 'kept': 47,\n",
              " 'until': 48,\n",
              " 'very': 49,\n",
              " 'end': 50,\n",
              " 'dialogue': 51,\n",
              " 'cheesy': 52,\n",
              " 'predictable': 53,\n",
              " 'visually': 54,\n",
              " 'powerful': 55,\n",
              " 'message': 56,\n",
              " 'any': 57,\n",
              " 'sci': 58,\n",
              " 'fi': 59,\n",
              " 'fan': 60,\n",
              " 'wooden': 61,\n",
              " 'looked': 62,\n",
              " 'cheap': 63,\n",
              " 'disappointment': 64,\n",
              " 'hilarious': 65,\n",
              " 'had': 66,\n",
              " 'laughing': 67,\n",
              " 'out': 68,\n",
              " 'loud': 69,\n",
              " 'throughout': 70,\n",
              " 'pick': 71,\n",
              " 'up': 72,\n",
              " 'pacing': 73,\n",
              " 'slow': 74,\n",
              " 'not': 75,\n",
              " 'my': 76,\n",
              " 'cup': 77,\n",
              " 'tea': 78,\n",
              " 'stay': 79,\n",
              " 'long': 80,\n",
              " 'after': 81,\n",
              " 'credits': 82,\n",
              " 'roll': 83,\n",
              " 'underdeveloped': 84,\n",
              " 'skippable': 85,\n",
              " 'delightful': 86,\n",
              " 'family': 87,\n",
              " 'something': 88,\n",
              " 'everyone': 89,\n",
              " 'great': 90,\n",
              " 'choice': 91,\n",
              " 'heartbreaking': 92,\n",
              " 'truly': 93,\n",
              " 'moving': 94,\n",
              " 'historical': 95,\n",
              " 'drama': 96,\n",
              " 'captured': 97,\n",
              " 'essence': 98,\n",
              " 'time': 99,\n",
              " 'period': 100,\n",
              " 'beautifully': 101,\n",
              " 'cinematography': 102,\n",
              " 'convoluted': 103,\n",
              " 'overcoming': 104,\n",
              " 'adversity': 105,\n",
              " 'tearjerker': 106,\n",
              " 'so': 107,\n",
              " 'bad': 108,\n",
              " 'it': 109,\n",
              " 'cult': 110,\n",
              " 'classic': 111,\n",
              " 'in': 112,\n",
              " 'making': 113,\n",
              " 'challenges': 114,\n",
              " 'societal': 115,\n",
              " 'norms': 116,\n",
              " 'see': 117,\n",
              " 'social': 118,\n",
              " 'commentary': 119,\n",
              " 'fans': 120,\n",
              " 'groundbreaking': 121,\n",
              " 'emotional': 122,\n",
              " 'well': 123,\n",
              " 'paced': 124,\n",
              " 'suspenseful': 125,\n",
              " 'thriller': 126,\n",
              " 'keep': 127,\n",
              " 'unsatisfying': 128,\n",
              " 'leave': 129,\n",
              " 'smile': 130,\n",
              " 'feel': 131,\n",
              " 'animation': 132,\n",
              " 'beautiful': 133,\n",
              " 'sheds': 134,\n",
              " 'light': 135,\n",
              " 'on': 136,\n",
              " 'critical': 137,\n",
              " 'issue': 138,\n",
              " 'anyone': 139,\n",
              " 'concerned': 140,\n",
              " 'topic': 141}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer           #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIxjUbNCa78_",
        "outputId": "503611e1-9773-4130-d66a-ddda8edd4358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.legacy.preprocessing.text.Tokenizer at 0x7c718e530310>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences   # Each review/sentence are constituded of these word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVGgn7ixbQng",
        "outputId": "28bea9a2-11f1-4644-edd3-6fa95a466a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19,\n",
              "  12,\n",
              "  3,\n",
              "  2,\n",
              "  43,\n",
              "  13,\n",
              "  44,\n",
              "  45,\n",
              "  1,\n",
              "  7,\n",
              "  3,\n",
              "  46,\n",
              "  4,\n",
              "  1,\n",
              "  8,\n",
              "  47,\n",
              "  14,\n",
              "  20,\n",
              "  48,\n",
              "  1,\n",
              "  49,\n",
              "  50],\n",
              " [1, 51, 3, 52, 4, 1, 21, 53, 2, 22, 12],\n",
              " [2, 54, 23, 9, 10, 2, 55, 56, 2, 15, 24, 5, 57, 58, 59, 60],\n",
              " [1, 7, 3, 61, 4, 1, 25, 26, 62, 63, 2, 64],\n",
              " [2, 65, 27, 6, 66, 14, 67, 68, 69, 70, 28, 5, 2, 71, 14, 72],\n",
              " [1, 73, 3, 74, 4, 1, 29, 30, 31, 75, 76, 77, 13, 78],\n",
              " [2, 32, 33, 34, 6, 16, 79, 10, 17, 80, 81, 1, 82, 83],\n",
              " [1, 35, 18, 84, 4, 1, 8, 36, 37, 85],\n",
              " [2, 86, 87, 9, 10, 88, 5, 89, 2, 90, 91, 5, 2, 12, 38],\n",
              " [1, 7, 3, 39, 4, 1, 8, 3, 92, 2, 93, 94, 9],\n",
              " [19, 95, 96, 97, 1, 98, 13, 1, 99, 100, 101],\n",
              " [1, 102, 3, 23, 11, 1, 21, 3, 103],\n",
              " [2, 40, 8, 41, 104, 105, 2, 106],\n",
              " [1, 7, 3, 107, 108, 109, 3, 42, 2, 110, 111, 112, 1, 113],\n",
              " [2, 32, 33, 9, 6, 114, 115, 116, 15, 117, 5, 118, 119, 120],\n",
              " [1, 25, 26, 18, 121, 11, 1, 8, 36, 122, 37],\n",
              " [2, 123, 124, 4, 125, 126, 6, 16, 127, 17, 20],\n",
              " [1, 7, 3, 39, 11, 1, 29, 30, 31, 4, 128],\n",
              " [2, 40, 27, 6, 16, 129, 17, 10, 2, 130, 28, 5, 2, 131, 42, 38],\n",
              " [1, 132, 3, 133, 11, 1, 35, 18, 22],\n",
              " [2, 34, 6, 134, 135, 136, 2, 137, 138, 2, 15, 24, 5, 139, 140, 41, 1, 141]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad_sequences to have a fixed length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=50 )  # Adjust maxlen as needed\n",
        "padded_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTHUhNaKfZzN",
        "outputId": "be25bee6-083f-4bde-f818-dadc1d285847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   1,  49,  50],\n",
              "       [  0,   0,   0, ...,   2,  22,  12],\n",
              "       [  0,   0,   0, ...,  58,  59,  60],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 131,  42,  38],\n",
              "       [  0,   0,   0, ...,  35,  18,  22],\n",
              "       [  0,   0,   0, ...,  41,   1, 141]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define vocabulary size and embedding dimension\n",
        "vocabulary_size = len(tokenizer.word_index)+ 1  # +1 FOR PADDING\n",
        "embedding_dim = 120      # Adjust Embedding dimension as needed\n",
        "print(vocabulary_size,embedding_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOMICNbE2P9s",
        "outputId": "0bf9c7c5-43f9-4bb1-82c2-03e70a3577c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "142 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create The Embedding layer\n",
        "embedding_layer = tf.keras.layers.Embedding(vocabulary_size,embedding_dim,input_length=100)  # Adjust input_length as needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndbVFm0y3KiD",
        "outputId": "70106f72-1b69-49e8-981f-91b583f62acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Classification Model\n",
        "model = tf.keras.Sequential()\n",
        "  # [ embedding_layer,\n",
        "  #  tf.keras.layers.Flatten(),\n",
        "  #  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  #  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "#])"
      ],
      "metadata": {
        "id": "RfO2F2Ji5Euf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(embedding_layer)"
      ],
      "metadata": {
        "id": "vrD1z77r62DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Flatten() )  # Flatten the embedded sequences"
      ],
      "metadata": {
        "id": "_5F4be3l7XuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(1, activation='softmax')) #OUTPUT LAYER"
      ],
      "metadata": {
        "id": "xAAjd-Gj7qQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # Adjust loss function as needed"
      ],
      "metadata": {
        "id": "MXy4A3He8MAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "IuTMe8R98xFu",
        "outputId": "19c36e77-4a85-44b8-c346-951d7dfa6932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m120\u001b[0m)             │          \u001b[38;5;34m17,040\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6000\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m6,001\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,040</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6000</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,001</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,125\u001b[0m (270.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,125</span> (270.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,041\u001b[0m (90.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,041</span> (90.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m46,084\u001b[0m (180.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,084</span> (180.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(padded_sequences,labels,epochs=10) # Model Trained so, it will perdict although accuracy isn't high due to small size of input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI62oMaCBBG8",
        "outputId": "ea371b1b-1b0d-4080-b826-ec78b58e1be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6190 - loss: 0.6998\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6190 - loss: 0.6719\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6190 - loss: 0.6483\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6190 - loss: 0.6286\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6190 - loss: 0.6120\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6190 - loss: 0.5977\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6190 - loss: 0.5847\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6190 - loss: 0.5719\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6190 - loss: 0.5585\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6190 - loss: 0.5441\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c7105c29d50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(new_sentence):\n",
        "  # Tokenize the new sentence\n",
        "  new_sequence = tokenizer.texts_to_sequences([new_sentence])\n",
        "\n",
        "  # Pad the new sequence to have the same length as the training data\n",
        "  new_padded_sequence = pad_sequences(new_sequence, maxlen=100)\n",
        "\n",
        "  #Predict sentiment\n",
        "  prediction = model.predict(new_padded_sequence)\n",
        "\n",
        "  # Extract the predicted class(positive or negative)\n",
        "  predicted_class = np.round(prediction[0][0]).astype(int)\n",
        "\n",
        "  # Interpret the prediction\n",
        "  if predicted_class == 1:\n",
        "    print(f\"Predicted sentiment for '{new_sentence}' : Positive \")\n",
        "  else:\n",
        "    print(f\"Predicted sentiment for '{new_sentence}' : Negative\")\n"
      ],
      "metadata": {
        "id": "jqqSY0AgBSAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "new_sentence = \"A thought-provoking documentary that will stay with you long after the credits roll.\"\n",
        "predict_sentiment(new_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHyhGAGhGjtY",
        "outputId": "1a7c02df-ca10-4aef-c794-0f16d9c7e780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "Predicted sentiment for 'A thought-provoking documentary that will stay with you long after the credits roll.' : Positive \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}